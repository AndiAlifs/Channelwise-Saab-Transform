{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saab transformationv 2021.04.12\n",
    "# modified from https://github.com/ChengyaoWang/PixelHop-_c-wSaab/blob/master/saab.py\n",
    "\n",
    "import numpy as np\n",
    "import numba\n",
    "# from sklearn.decomposition import PCA, IncrementalPCA\n",
    "\n",
    "\n",
    "@numba.jit(nopython = True, parallel = True)\n",
    "def pca_cal(X: np.ndarray):\n",
    "    cov = X.transpose() @ X\n",
    "    eva, eve = np.linalg.eigh(cov)\n",
    "    inds = eva.argsort()[::-1]\n",
    "    eva = eva[inds]\n",
    "    kernels = eve.transpose()[inds]\n",
    "    return kernels, eva / (X.shape[0] - 1)\n",
    "\n",
    "@numba.jit(forceobj = True, parallel = True)\n",
    "def remove_mean(X: np.ndarray, feature_mean: np.ndarray):\n",
    "    return X - feature_mean\n",
    "\n",
    "@numba.jit(nopython = True, parallel = True)\n",
    "def feat_transform(X: np.ndarray, kernel: np.ndarray):\n",
    "    return X @ kernel.transpose()\n",
    "\n",
    "\n",
    "class Saab():\n",
    "    def __init__(self, num_kernels=-1, needBias=True, bias=0):\n",
    "        self.num_kernels = num_kernels \n",
    "        self.needBias = needBias\n",
    "        self.Bias_previous = bias # bias calculated from previous\n",
    "        self.Bias_current = [] # bias for the current Hop\n",
    "        self.Kernels = []\n",
    "        self.Mean0 = [] # feature mean of AC\n",
    "        self.Energy = [] # kernel energy list\n",
    "        self.trained = False\n",
    "\n",
    "    def fit(self, X): \n",
    "        assert (len(X.shape) == 2), \"Input must be a 2D array!\"\n",
    "        X = X.astype('float32')\n",
    "        \n",
    "        # add bias from the previous Hop\n",
    "        if self.needBias == True:\n",
    "            X += self.Bias_previous\n",
    "            \n",
    "        # remove DC, get AC components\n",
    "        dc = np.mean(X, axis = 1, keepdims = True)\n",
    "        X = remove_mean(X, dc)\n",
    "        \n",
    "        # calcualte bias at the current Hop\n",
    "        self.Bias_current = np.max(np.linalg.norm(X, axis=1))\n",
    "        \n",
    "        # remove feature mean --> self.Mean0\n",
    "        self.Mean0 = np.mean(X, axis = 0, keepdims = True)\n",
    "        X = remove_mean(X, self.Mean0)\n",
    "\n",
    "        if self.num_kernels == -1:\n",
    "            self.num_kernels = X.shape[-1]\n",
    "        \n",
    "        # Rewritten PCA Using Numpy\n",
    "        kernels, eva = pca_cal(X)\n",
    "        \n",
    "        # Concatenate with DC kernel\n",
    "        dc_kernel = 1 / np.sqrt(X.shape[-1]) * np.ones((1, X.shape[-1]))# / np.sqrt(largest_ev)\n",
    "        kernels = np.concatenate((dc_kernel, kernels[:-1]), axis = 0)\n",
    "        \n",
    "        # Concatenate with DC energy\n",
    "        largest_ev = np.var(dc * np.sqrt(X.shape[-1]))  \n",
    "        energy = np.concatenate((np.array([largest_ev]), eva[:-1]), axis = 0)\n",
    "        energy = energy / np.sum(energy)\n",
    "        \n",
    "        # store\n",
    "        self.Kernels, self.Energy = kernels.astype('float32'), energy\n",
    "        self.trained = True\n",
    "\n",
    "\n",
    "    def transform(self, X):\n",
    "        assert (self.trained == True), \"Must call fit first!\"\n",
    "        X = X.astype('float32')\n",
    "        \n",
    "        # add bias from the previous Hop\n",
    "        if self.needBias == True:\n",
    "            X += self.Bias_previous\n",
    "            \n",
    "        # remove feature mean of AC\n",
    "        X = remove_mean(X, self.Mean0)\n",
    "        \n",
    "        # convolve with DC and AC filters\n",
    "        X = feat_transform(X, self.Kernels)\n",
    "        \n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all images from covid-chestxray-dataset/images\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "# list all files in covid-chestxray-dataset/images\n",
    "path = 'covid-chestxray-dataset/images'\n",
    "files = os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[ 38]\n",
      "   [ 38]\n",
      "   [ 38]\n",
      "   ...\n",
      "   [ 43]\n",
      "   [ 43]\n",
      "   [ 43]]\n",
      "\n",
      "  [[ 45]\n",
      "   [ 45]\n",
      "   [ 44]\n",
      "   ...\n",
      "   [106]\n",
      "   [104]\n",
      "   [104]]\n",
      "\n",
      "  [[101]\n",
      "   [103]\n",
      "   [101]\n",
      "   ...\n",
      "   [ 71]\n",
      "   [ 71]\n",
      "   [ 71]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[115]\n",
      "   [116]\n",
      "   [115]\n",
      "   ...\n",
      "   [115]\n",
      "   [116]\n",
      "   [115]]\n",
      "\n",
      "  [[115]\n",
      "   [117]\n",
      "   [115]\n",
      "   ...\n",
      "   [118]\n",
      "   [117]\n",
      "   [120]]\n",
      "\n",
      "  [[119]\n",
      "   [117]\n",
      "   [119]\n",
      "   ...\n",
      "   [133]\n",
      "   [133]\n",
      "   [132]]]]\n",
      " input feature shape: (1, 420, 512, 1)\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread(os.path.join(path, files[0]), cv2.IMREAD_GRAYSCALE)\n",
    "img = cv2.resize(img, (420, 512))\n",
    "img = img.reshape(1, 420, 512, 1)\n",
    "\n",
    "print(img)\n",
    "print(\" input feature shape: %s\"%str(img.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " input feature shape: (930, 420, 512, 1)\n"
     ]
    }
   ],
   "source": [
    "datasets = []\n",
    "for i in range(len(files)):\n",
    "    img = cv2.imread(os.path.join(path, files[i]), cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img, (420, 512))\n",
    "    img = img.reshape(1, 420, 512, 1)\n",
    "    datasets.append(img)\n",
    "\n",
    "datasets = np.concatenate(datasets, axis = 0)\n",
    "print(\" input feature shape: %s\"%str(datasets.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " input feature shape: (50, 215040)\n"
     ]
    }
   ],
   "source": [
    "X = datasets.copy()\n",
    "X = X.reshape(X.shape[0], -1)[0:50]\n",
    "print(\" input feature shape: %s\"%str(X.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Allocation failed (probably too large).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m saab \u001b[39m=\u001b[39m Saab(num_kernels\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, needBias\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, bias\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m saab\u001b[39m.\u001b[39;49mfit(X)\n",
      "Cell \u001b[0;32mIn[1], line 61\u001b[0m, in \u001b[0;36mSaab.fit\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_kernels \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m     60\u001b[0m \u001b[39m# Rewritten PCA Using Numpy\u001b[39;00m\n\u001b[0;32m---> 61\u001b[0m kernels, eva \u001b[39m=\u001b[39m pca_cal(X)\n\u001b[1;32m     63\u001b[0m \u001b[39m# Concatenate with DC kernel\u001b[39;00m\n\u001b[1;32m     64\u001b[0m dc_kernel \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m \u001b[39m/\u001b[39m np\u001b[39m.\u001b[39msqrt(X\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]) \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39mones((\u001b[39m1\u001b[39m, X\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]))\u001b[39m# / np.sqrt(largest_ev)\u001b[39;00m\n",
      "\u001b[0;31mMemoryError\u001b[0m: Allocation failed (probably too large)."
     ]
    }
   ],
   "source": [
    "saab = Saab(num_kernels=-1, needBias=True, bias=0)\n",
    "saab.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
